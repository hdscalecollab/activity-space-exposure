{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure Analysis with Point Overlaying Background Layer (Raster)\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////////\n",
    "##### Author: Jay (Jiue-An) Yang, @JiueAnYang\n",
    "##### Organization: Health Data at Scale Collaboratory, City of Hope\n",
    "##### Last Updated: December 20, 2023\n",
    "////////////////////////////////////////////////////////////////////////////////////\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements:\n",
    "##### 1. A file directory with .csv files containing GPS points\n",
    "##### 2. A file directory with raster files of env variables that needs to be processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Model Workflow as in ArcGIS Model Builder\n",
    "\n",
    "![Alt text](exposure_PointOverlay_v5.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required modules\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "import glob, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## Set environment options\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "## Set environment variables\n",
    "env.workspace = r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb\"  # workspace: your project .gdb name\n",
    "project_dir = r\"C:/Users/Jay-PC/Desktop/Test/\"                                   # directory\n",
    "gps_data_dir = r\"C:/Users/Jay-PC/Desktop/Test/Testing/test_data_csv/\"            # directory\n",
    "gps_data_dir = r\"C:/Users/Jay-PC/Documents/UCSD/PQ/Outputs/from_PY/0918_2020/Stationary/\"  # directory  Testing entire Folder\n",
    "\n",
    "x_cord_name = 'lng'                                            # column name for x coordinates in point csv \n",
    "y_cord_name = 'lat'                                            # column name for y coordinates in point csv \n",
    "final_output_table_temp = env.workspace + \"/table_temp\"      # temporary table each loop \n",
    "final_output_table = env.workspace + \"/final_output_table_PO\"  # table name for final output in .gdb\n",
    "final_output_table_output_dir = r\"C:/Users/Jay-PC/Desktop/Test/\"         # directory\n",
    "final_output_table_csv_name = \"Exposure_PointOverlay.csv\"      # filename for final output in .csv format\n",
    "\n",
    "## Set path to some specific layers\n",
    "research_area = r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb/SD_County_Boundary_proj\"        # shapefile or feature class \n",
    "\n",
    "## Set the list of input Raster that will be overlay: format as [Raster, {Output Field Name}]\n",
    "exposure_rasters = [[r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb/FastFood2014\",\"FastFood2014\"],     \n",
    "                    [r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb/BikeRoutes\",\"BikeRoutes\"],\n",
    "                    [r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb/ParkArea2016\",\"ParkArea2016\"],\n",
    "                    [r\"C:/Users/Jay-PC/Desktop/Test/Point-Overlay-Input-Rasters.gdb/NO2Mean2019\",\"NO2Mean2019\"]]\n",
    "exposure_fields = [\"FastFood2014\",\"BikeRoutes\",\"ParkArea2016\",\"NO2Mean2019\"]\n",
    "\n",
    "\n",
    "## Specify spatial reference for the analysis\n",
    "spatial_ref = arcpy.SpatialReference('North America Albers Equal Area Conic')\n",
    "\n",
    "## Specify spatial reference for the analysis\n",
    "## getting ID from filename, example: \"SD_points_PQ010122.csv\" --> \"PQ010122\"\n",
    "pt_ID_start = -12\n",
    "pt_ID_end  = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clear final output table if there is data inside\n",
    "if arcpy.Exists(final_output_table):\n",
    "    arcpy.Delete_management(final_output_table)\n",
    "\n",
    "if arcpy.Exists(final_output_table_temp):\n",
    "    arcpy.Delete_management(final_output_table_temp)\n",
    "\n",
    "    \n",
    "### Create a log file\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "log_file_name = \"log_\" + dt_string + \".txt\"\n",
    "f = open(log_file_name, \"a\")\n",
    "\n",
    "\n",
    "### Placeholders \n",
    "stats_frames = []       ## dataframe for writing .csv results \n",
    "non_processed_pts = []  ## list to store non-processed PTs\n",
    "\n",
    "### Loop through .csv files in the data directory\n",
    "start = time.time()\n",
    "i = 1\n",
    "total_i = len(glob.glob(gps_data_dir + \"*\"))\n",
    "\n",
    "for file in glob.glob(gps_data_dir + \"*.csv\"):\n",
    "# for file in glob.glob(gps_data_dir + \"*.csv\")[:1]:   # This will only run the first two PTs in the directory, for testing\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    ## check if file is .csv\n",
    "    if file[-4:] == '.csv':\n",
    "        \n",
    "        pt_ID = file[pt_ID_start:pt_ID_end]\n",
    "        msg = \"Working on : {pt} ({index}/{total})\".format(pt = pt_ID, index = i, total= total_i)\n",
    "        print (msg)\n",
    "        \n",
    "        ### make sure there are points in the .csv\n",
    "        df = pd.read_csv(file)\n",
    "        if len(df) > 0:\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 1: Create feature class from CSV points\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.management.XYTableToPoint(file, \"point_fc\", x_cord_name, y_cord_name, \"\", arcpy.SpatialReference(4326))\n",
    "            print (\"Step 1: csv converted to feature class\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 2: Re-project feature class\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.Project_management(\"point_fc\", \"point_fc_proj\", spatial_ref)\n",
    "            print (\"Step 2: feature class re-projected to - \", spatial_ref.name)\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 3: Clip feature class by analysis extent\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            arcpy.Clip_analysis(\"point_fc_proj\", research_area, \"point_fc_cliped\")\n",
    "            print (\"Step 3: feature class clipped by research area\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 4: Extract Overlay VValues from Raster\n",
    "            ### method will update existing point FC with new columns\n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            ExtractMultiValuesToPoints(\"point_fc_cliped\", exposure_rasters, \"NONE\")   \n",
    "            print (\"Step 4: extracte raster values to points\")\n",
    "\n",
    "            ### --------------------------------------------------------\n",
    "            ### Step 5: Run Summary Statistics for the exposure fields \n",
    "            ### --------------------------------------------------------\n",
    "\n",
    "            ## create the statistics fields to run summary on\n",
    "            stat_categories = ['SUM',\"MEAN\",\"MIN\",\"MAX\",\"RANGE\",\"STD\",\"MEDIAN\",\"VARIANCE\",\"COUNT\"]\n",
    "            stat_fields = []\n",
    "            for exp in exposure_fields:\n",
    "                for st in stat_categories:\n",
    "                    stat_fields.append([exp,st])\n",
    "\n",
    "            ## run summary statistics\n",
    "            arcpy.Statistics_analysis(\"point_fc_cliped\", final_output_table_temp, stat_fields)\n",
    "            print (\"Step 5: calculate summary statistics on exposure fields\")\n",
    "\n",
    "            ## Get a list of field names to display\n",
    "            field_names = [i.name for i in arcpy.ListFields(final_output_table_temp) if i.type != 'OID']\n",
    "\n",
    "            ## Open a cursor to extract results from stats table\n",
    "            cursor = arcpy.da.SearchCursor(final_output_table_temp, field_names)\n",
    "\n",
    "            ## Create a pandas dataframe to display results\n",
    "            df = pd.DataFrame(data=[row for row in cursor],\n",
    "                                  columns=field_names)\n",
    "\n",
    "            df['PT_ID'] = pt_ID\n",
    "            stats_frames.append(df)\n",
    " \n",
    "        else:  ### Write to log file to record this pt without points\n",
    "            non_processed_pts.append(pt_ID)\n",
    "            f.write(\"Participant ID: {} was not processed.\\n\".format(pt_ID))\n",
    "                        \n",
    "        i+=1\n",
    "\n",
    "        \n",
    "### ------------------------------------------------------------------------------------\n",
    "### Step 6: Concat PT outputs to one datafram, write to .csv and write to table in gdb\n",
    "### ------------------------------------------------------------------------------------\n",
    "\n",
    "### Check if there are resutls to be processed first \n",
    "if len(stats_frames) > 0:\n",
    "    final_df = pd.concat(stats_frames)  \n",
    "\n",
    "    ## add non-processed PTs to the final table\n",
    "    df_non_processed =pd.DataFrame(non_processed_pts,columns=['PT_ID'])\n",
    "    final_df = final_df.append(df_non_processed)\n",
    "\n",
    "    ## move PT_ID column to the front \n",
    "    col_name=\"PT_ID\"\n",
    "    first_col = final_df.pop(col_name)\n",
    "    final_df.insert(0, col_name, first_col)\n",
    "    \n",
    "    ## write results to .csv file \n",
    "    final_df.to_csv(final_output_table_output_dir + final_output_table_csv_name, index = False)\n",
    "    \n",
    "    ## Close the log file\n",
    "    f.close()\n",
    "\n",
    "    ## write results into workspace gdb\n",
    "    ## Note !!  NumPyArrayToTable will not overwrite an existing table\n",
    "    ## so check if there is already a table with the same filename there\n",
    "    x = np.array(np.rec.fromrecords(final_df.values))\n",
    "    names = final_df.dtypes.index.tolist()\n",
    "    x.dtype.names = tuple(names)\n",
    "    arcpy.da.NumPyArrayToTable(x, final_output_table)\n",
    "\n",
    "    end = time.time()\n",
    "    print (\"-\"*30)\n",
    "    print (\"Exposure Analysis with PointOverlay Completed, total time spent : \", end - start)\n",
    "    print (\"Output table available at : \", final_output_table_output_dir + final_output_table_csv_name)\n",
    "    print (\"Please also check the log file at : {}\".format(log_file_name))\n",
    "    \n",
    "    ## Final output table is saved as a .csv file in the defined [final_output_table_output_dir] location.\n",
    "    ## Final output table is also write to your workspace gdb\n",
    "\n",
    "### if there are no resutls to be processed, write to the log file.\n",
    "else:\n",
    "    ### Close the log file\n",
    "    f.write(\"-\"*30)\n",
    "    f.write(\"\\nThere are no exposure resutls for the entire run.\")\n",
    "    f.close()\n",
    "    print (\"-\"*30)\n",
    "    print (\"There are no exposure resutls for the entire run.\")\n",
    "    print (\"Please also check the log file at : {}\".format(log_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3-clone",
   "language": "python",
   "name": "arcgispro-py3-clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
